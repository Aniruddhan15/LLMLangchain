{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea26c366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599c8552",
   "metadata": {},
   "source": [
    "Approaches:\n",
    "\n",
    "1. Chains in whihc we execute retreieval step\n",
    "2. Agents, where we give LLM discretion over whether and how to execute a retreival step (or multiple steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d026d5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27407ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f179850",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = os.getenv(\"GROQ_API_Key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bdda13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002D6E63F3E20>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002D6E642D2D0>, model_name='Llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatGroq(groq_api_key=groq_api_key, model=\"Llama3-8b-8192\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d82ae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['HF_TOKEN'] = os.getenv(\"HF_TOKEN\")\n",
    "#from langchain_huggingface import HuggingFaceEmbedings\n",
    "# embeddings =  HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff0471f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fc569cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09c29cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model='gemma:2b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91cf0ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://python.langchain.com/docs/tutorials/agents/\",),\n",
    "\n",
    ")\n",
    "\n",
    "docs=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d42dfb41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='\\n\\n\\n\\n\\nBuild an Agent | ü¶úÔ∏èüîó LangChain\\n\\n\\n\\n\\n\\n\\nSkip to main contentWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith.  Join our team!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1üí¨SearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain\\'s stateHow to construct filters for query analysisHow to configure runtime chain internalsHow deal with high cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse text from message objectsHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with langchainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystemü¶úüõ†Ô∏è LangSmithü¶úüï∏Ô∏è LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyTutorialsBuild an AgentOn this pageBuild an Agent\\nBy themselves, language models can\\'t take actions - they just output text.\\nA big use case for LangChain is creating agents.\\nAgents are systems that use LLMs as reasoning engines to determine which actions to take and the inputs necessary to perform the action.\\nAfter executing actions, the results can be fed back into the LLM to determine whether more actions are needed, or whether it is okay to finish. This is often achieved via tool-calling.\\nIn this tutorial we will build an agent that can interact with a search engine. You will be able to ask this agent questions, watch it call the search tool, and have conversations with it.\\nEnd-to-end agent\\u200b\\nThe code snippet below represents a fully functional agent that uses an LLM to decide which tools to use. It is equipped with a generic search tool. It has conversational memory - meaning that it can be used as a multi-turn chatbot.\\nIn the rest of the guide, we will walk through the individual components and what each part does - but if you want to just grab some code and get started, feel free to use this!\\n# Import relevant functionalityfrom langchain_anthropic import ChatAnthropicfrom langchain_community.tools.tavily_search import TavilySearchResultsfrom langchain_core.messages import HumanMessagefrom langgraph.checkpoint.memory import MemorySaverfrom langgraph.prebuilt import create_react_agent# Create the agentmemory = MemorySaver()model = ChatAnthropic(model_name=\"claude-3-sonnet-20240229\")search = TavilySearchResults(max_results=2)tools = [search]agent_executor = create_react_agent(model, tools, checkpointer=memory)API Reference:ChatAnthropic | TavilySearchResults | HumanMessage | MemorySaver | create_react_agent\\n# Use the agentconfig = {\"configurable\": {\"thread_id\": \"abc123\"}}for step in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"hi im bob! and i live in sf\")]},    config,    stream_mode=\"values\",):    step[\"messages\"][-1].pretty_print()\\n================================\\x1b[1m Human Message \\x1b[0m=================================hi im bob! and i live in sf==================================\\x1b[1m Ai Message \\x1b[0m==================================Hello Bob! Since you didn\\'t ask a specific question, I don\\'t need to use any tools right now. I\\'m an AI assistant created by Anthropic to be helpful, honest, and harmless. Feel free to ask me anything and I\\'ll do my best to provide a useful response or look up information using my capabilities.\\nfor step in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"whats the weather where I live?\")]},    config,    stream_mode=\"values\",):    step[\"messages\"][-1].pretty_print()\\n================================\\x1b[1m Human Message \\x1b[0m=================================whats the weather where I live?==================================\\x1b[1m Ai Message \\x1b[0m==================================[{\\'text\\': \\'To get the current weather for your location in San Francisco, I can use the tavily_search_results_json tool:\\', \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01AKa2MErG1CU3zRiGsvpBud\\', \\'input\\': {\\'query\\': \\'san francisco weather\\'}, \\'name\\': \\'tavily_search_results_json\\', \\'type\\': \\'tool_use\\'}]Tool Calls:  tavily_search_results_json (toolu_01AKa2MErG1CU3zRiGsvpBud) Call ID: toolu_01AKa2MErG1CU3zRiGsvpBud  Args:    query: san francisco weather=================================\\x1b[1m Tool Message \\x1b[0m=================================Name: tavily_search_results_json[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.775, \\'lon\\': -122.4183, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1739994486, \\'localtime\\': \\'2025-02-19 11:48\\'}, \\'current\\': {\\'last_updated_epoch\\': 1739994300, \\'last_updated\\': \\'2025-02-19 11:45\\', \\'temp_c\\': 13.3, \\'temp_f\\': 55.9, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Light rain\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/296.png\\', \\'code\\': 1183}, \\'wind_mph\\': 5.8, \\'wind_kph\\': 9.4, \\'wind_degree\\': 195, \\'wind_dir\\': \\'SSW\\', \\'pressure_mb\\': 1023.0, \\'pressure_in\\': 30.2, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 87, \\'cloud\\': 100, \\'feelslike_c\\': 12.7, \\'feelslike_f\\': 54.8, \\'windchill_c\\': 9.1, \\'windchill_f\\': 48.4, \\'heatindex_c\\': 10.2, \\'heatindex_f\\': 50.3, \\'dewpoint_c\\': 9.8, \\'dewpoint_f\\': 49.7, \\'vis_km\\': 4.0, \\'vis_miles\\': 2.0, \\'uv\\': 1.4, \\'gust_mph\\': 8.9, \\'gust_kph\\': 14.4}}\"}, {\"url\": \"https://world-weather.info/forecast/usa/san_francisco/february-2025/\", \"content\": \"Weather in San Francisco in February 2025 (California) - Detailed Weather Forecast for a Month Weather World Weather in San Francisco Weather in San Francisco in February 2025 San Francisco Weather Forecast for February 2025, is based on previous years\\' statistical data. +59¬∞+50¬∞ +59¬∞+52¬∞ +59¬∞+50¬∞ +61¬∞+52¬∞ +59¬∞+50¬∞ +61¬∞+50¬∞ +61¬∞+52¬∞ +63¬∞+52¬∞ +61¬∞+52¬∞ +61¬∞+50¬∞ +61¬∞+50¬∞ +61¬∞+50¬∞ +59¬∞+50¬∞ +59¬∞+50¬∞ +61¬∞+50¬∞ +61¬∞+52¬∞ +59¬∞+50¬∞ +59¬∞+48¬∞ +57¬∞+48¬∞ +59¬∞+50¬∞ +59¬∞+48¬∞ +59¬∞+50¬∞ +57¬∞+46¬∞ +61¬∞+50¬∞ +61¬∞+50¬∞ +59¬∞+50¬∞ +59¬∞+48¬∞ +59¬∞+50¬∞ Extended weather forecast in San Francisco HourlyWeek10-Day14-Day30-DayYear Weather in large and nearby cities Weather in Washington, D.C.+41¬∞ Sacramento+55¬∞ Pleasanton+55¬∞ Redwood City+55¬∞ San Leandro+55¬∞ San Mateo+54¬∞ San Rafael+52¬∞ San Ramon+52¬∞ South San Francisco+54¬∞ Vallejo+50¬∞ Palo Alto+55¬∞ Pacifica+55¬∞ Berkeley+54¬∞ Castro Valley+55¬∞ Concord+52¬∞ Daly City+54¬∞ Noverd+52¬∞ Sign Hill+54¬∞ world\\'s temperature today day day Temperature units\"}]==================================\\x1b[1m Ai Message \\x1b[0m==================================The search results provide the current weather conditions and forecast for San Francisco. According to the data from WeatherAPI, the current temperature in San Francisco is around 55¬∞F (13¬∞C) with light rain and winds around 6 mph. The extended forecast shows temperatures ranging from the upper 40s to low 60s Fahrenheit over the next few weeks.So in summary, it\\'s a cool, rainy day currently in San Francisco where you live, Bob. Let me know if you need any other details about the weather there!\\nSetup\\u200b\\nJupyter Notebook\\u200b\\nThis guide (and most of the other guides in the documentation) uses Jupyter notebooks and assumes the reader is as well. Jupyter notebooks are perfect interactive environments for learning how to work with LLM systems because oftentimes things can go wrong (unexpected output, API down, etc), and observing these cases is a great way to better understand building with LLMs.\\nThis and other tutorials are perhaps most conveniently run in a Jupyter notebook. See here for instructions on how to install.\\nInstallation\\u200b\\nTo install LangChain run:\\n%pip install -U langchain-community langgraph langchain-anthropic tavily-python langgraph-checkpoint-sqlite\\nFor more details, see our Installation guide.\\nLangSmith\\u200b\\nMany of the applications you build with LangChain will contain multiple steps with multiple invocations of LLM calls.\\nAs these applications get more and more complex, it becomes crucial to be able to inspect what exactly is going on inside your chain or agent.\\nThe best way to do this is with LangSmith.\\nAfter you sign up at the link above, make sure to set your environment variables to start logging traces:\\nexport LANGSMITH_TRACING=\"true\"export LANGSMITH_API_KEY=\"...\"\\nOr, if in a notebook, you can set them with:\\nimport getpassimport osos.environ[\"LANGSMITH_TRACING\"] = \"true\"os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()\\nTavily\\u200b\\nWe will be using Tavily (a search engine) as a tool.\\nIn order to use it, you will need to get and set an API key:\\nexport TAVILY_API_KEY=\"...\"\\nOr, if in a notebook, you can set it with:\\nimport getpassimport osos.environ[\"TAVILY_API_KEY\"] = getpass.getpass()\\nDefine tools\\u200b\\nWe first need to create the tools we want to use. Our main tool of choice will be Tavily - a search engine. We have a built-in tool in LangChain to easily use Tavily search engine as tool.\\nfrom langchain_community.tools.tavily_search import TavilySearchResultssearch = TavilySearchResults(max_results=2)search_results = search.invoke(\"what is the weather in SF\")print(search_results)# If we want, we can create other tools.# Once we have all the tools we want, we can put them in a list that we will reference later.tools = [search]API Reference:TavilySearchResults\\n[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.775, \\'lon\\': -122.4183, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1739993250, \\'localtime\\': \\'2025-02-19 11:27\\'}, \\'current\\': {\\'last_updated_epoch\\': 1739992500, \\'last_updated\\': \\'2025-02-19 11:15\\', \\'temp_c\\': 13.3, \\'temp_f\\': 55.9, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Light rain\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/296.png\\', \\'code\\': 1183}, \\'wind_mph\\': 5.8, \\'wind_kph\\': 9.4, \\'wind_degree\\': 195, \\'wind_dir\\': \\'SSW\\', \\'pressure_mb\\': 1023.0, \\'pressure_in\\': 30.2, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 87, \\'cloud\\': 100, \\'feelslike_c\\': 12.7, \\'feelslike_f\\': 54.8, \\'windchill_c\\': 9.1, \\'windchill_f\\': 48.4, \\'heatindex_c\\': 10.2, \\'heatindex_f\\': 50.3, \\'dewpoint_c\\': 9.8, \\'dewpoint_f\\': 49.7, \\'vis_km\\': 4.0, \\'vis_miles\\': 2.0, \\'uv\\': 1.4, \\'gust_mph\\': 8.9, \\'gust_kph\\': 14.4}}\"}, {\\'url\\': \\'https://weathershogun.com/weather/usa/ca/san-francisco/480/february/2025-02-19\\', \\'content\\': \\'San Francisco, California Weather: Wednesday, February 19, 2025. Cloudy weather, overcast skies with clouds. Day 61¬∞. Night 43¬∞.\\'}]\\nUsing Language Models\\u200b\\nNext, let\\'s learn how to use a language model to call tools. LangChain supports many different language models that you can use interchangably - select the one you want to use below!\\n\\nSelect chat model:Google Gemini‚ñæOpenAIAnthropicAzureGoogle GeminiGoogle VertexAWSGroqCohereNVIDIAFireworks AIMistral AITogether AIIBM watsonxDatabricksxAIPerplexitypip install -qU \"langchain[google-genai]\"import getpassimport osif not os.environ.get(\"GOOGLE_API_KEY\"):  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")from langchain.chat_models import init_chat_modelmodel = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")\\nYou can call the language model by passing in a list of messages. By default, the response is a content string.\\nfrom langchain_core.messages import HumanMessageresponse = model.invoke([HumanMessage(content=\"hi!\")])response.contentAPI Reference:HumanMessage\\n\\'Hi there!\\'\\nWe can now see what it is like to enable this model to do tool calling. In order to enable that we use .bind_tools to give the language model knowledge of these tools\\nmodel_with_tools = model.bind_tools(tools)\\nWe can now call the model. Let\\'s first call it with a normal message, and see how it responds. We can look at both the content field as well as the tool_calls field.\\nresponse = model_with_tools.invoke([HumanMessage(content=\"Hi!\")])print(f\"ContentString: {response.content}\")print(f\"ToolCalls: {response.tool_calls}\")\\nContentString: Hello!ToolCalls: []\\nNow, let\\'s try calling it with some input that would expect a tool to be called.\\nresponse = model_with_tools.invoke([HumanMessage(content=\"What\\'s the weather in SF?\")])print(f\"ContentString: {response.content}\")print(f\"ToolCalls: {response.tool_calls}\")\\nContentString: ToolCalls: [{\\'name\\': \\'tavily_search_results_json\\', \\'args\\': {\\'query\\': \\'weather san francisco\\'}, \\'id\\': \\'toolu_01VTP7DUvSfgtYxsq9x4EwMp\\'}]\\nWe can see that there\\'s now no text content, but there is a tool call! It wants us to call the Tavily Search tool.\\nThis isn\\'t calling that tool yet - it\\'s just telling us to. In order to actually call it, we\\'ll want to create our agent.\\nCreate the agent\\u200b\\nNow that we have defined the tools and the LLM, we can create the agent. We will be using LangGraph to construct the agent.\\nCurrently, we are using a high level interface to construct the agent, but the nice thing about LangGraph is that this high-level interface is backed by a low-level, highly controllable API in case you want to modify the agent logic.\\nNow, we can initialize the agent with the LLM and the tools.\\nNote that we are passing in the model, not model_with_tools. That is because create_react_agent will call .bind_tools for us under the hood.\\nfrom langgraph.prebuilt import create_react_agentagent_executor = create_react_agent(model, tools)API Reference:create_react_agent\\nRun the agent\\u200b\\nWe can now run the agent with a few queries! Note that for now, these are all stateless queries (it won\\'t remember previous interactions). Note that the agent will return the final state at the end of the interaction (which includes any inputs, we will see later on how to get only the outputs).\\nFirst up, let\\'s see how it responds when there\\'s no need to call a tool:\\nresponse = agent_executor.invoke({\"messages\": [HumanMessage(content=\"hi!\")]})response[\"messages\"]\\n[HumanMessage(content=\\'hi!\\', id=\\'a820fcc5-9b87-457a-9af0-f21768143ee3\\'), AIMessage(content=\\'Hello!\\', response_metadata={\\'id\\': \\'msg_01VbC493X1VEDyusgttiEr1z\\', \\'model\\': \\'claude-3-sonnet-20240229\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 264, \\'output_tokens\\': 5}}, id=\\'run-0e0ddae8-a85b-4bd6-947c-c36c857a4698-0\\', usage_metadata={\\'input_tokens\\': 264, \\'output_tokens\\': 5, \\'total_tokens\\': 269})]\\nIn order to see exactly what is happening under the hood (and to make sure it\\'s not calling a tool) we can take a look at the LangSmith trace\\nLet\\'s now try it out on an example where it should be invoking the tool\\nresponse = agent_executor.invoke(    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]})response[\"messages\"]\\n[HumanMessage(content=\\'whats the weather in sf?\\', id=\\'1d6c96bb-4ddb-415c-a579-a07d5264de0d\\'), AIMessage(content=[{\\'id\\': \\'toolu_01Y5EK4bw2LqsQXeaUv8iueF\\', \\'input\\': {\\'query\\': \\'weather in san francisco\\'}, \\'name\\': \\'tavily_search_results_json\\', \\'type\\': \\'tool_use\\'}], response_metadata={\\'id\\': \\'msg_0132wQUcEduJ8UKVVVqwJzM4\\', \\'model\\': \\'claude-3-sonnet-20240229\\', \\'stop_reason\\': \\'tool_use\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 269, \\'output_tokens\\': 61}}, id=\\'run-26d5e5e8-d4fd-46d2-a197-87b95b10e823-0\\', tool_calls=[{\\'name\\': \\'tavily_search_results_json\\', \\'args\\': {\\'query\\': \\'weather in san francisco\\'}, \\'id\\': \\'toolu_01Y5EK4bw2LqsQXeaUv8iueF\\'}], usage_metadata={\\'input_tokens\\': 269, \\'output_tokens\\': 61, \\'total_tokens\\': 330}), ToolMessage(content=\\'[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\\\\\'location\\\\\\': {\\\\\\'name\\\\\\': \\\\\\'San Francisco\\\\\\', \\\\\\'region\\\\\\': \\\\\\'California\\\\\\', \\\\\\'country\\\\\\': \\\\\\'United States of America\\\\\\', \\\\\\'lat\\\\\\': 37.78, \\\\\\'lon\\\\\\': -122.42, \\\\\\'tz_id\\\\\\': \\\\\\'America/Los_Angeles\\\\\\', \\\\\\'localtime_epoch\\\\\\': 1717238703, \\\\\\'localtime\\\\\\': \\\\\\'2024-06-01 3:45\\\\\\'}, \\\\\\'current\\\\\\': {\\\\\\'last_updated_epoch\\\\\\': 1717237800, \\\\\\'last_updated\\\\\\': \\\\\\'2024-06-01 03:30\\\\\\', \\\\\\'temp_c\\\\\\': 12.0, \\\\\\'temp_f\\\\\\': 53.6, \\\\\\'is_day\\\\\\': 0, \\\\\\'condition\\\\\\': {\\\\\\'text\\\\\\': \\\\\\'Mist\\\\\\', \\\\\\'icon\\\\\\': \\\\\\'//cdn.weatherapi.com/weather/64x64/night/143.png\\\\\\', \\\\\\'code\\\\\\': 1030}, \\\\\\'wind_mph\\\\\\': 5.6, \\\\\\'wind_kph\\\\\\': 9.0, \\\\\\'wind_degree\\\\\\': 310, \\\\\\'wind_dir\\\\\\': \\\\\\'NW\\\\\\', \\\\\\'pressure_mb\\\\\\': 1013.0, \\\\\\'pressure_in\\\\\\': 29.92, \\\\\\'precip_mm\\\\\\': 0.0, \\\\\\'precip_in\\\\\\': 0.0, \\\\\\'humidity\\\\\\': 88, \\\\\\'cloud\\\\\\': 100, \\\\\\'feelslike_c\\\\\\': 10.5, \\\\\\'feelslike_f\\\\\\': 50.8, \\\\\\'windchill_c\\\\\\': 9.3, \\\\\\'windchill_f\\\\\\': 48.7, \\\\\\'heatindex_c\\\\\\': 11.1, \\\\\\'heatindex_f\\\\\\': 51.9, \\\\\\'dewpoint_c\\\\\\': 8.8, \\\\\\'dewpoint_f\\\\\\': 47.8, \\\\\\'vis_km\\\\\\': 6.4, \\\\\\'vis_miles\\\\\\': 3.0, \\\\\\'uv\\\\\\': 1.0, \\\\\\'gust_mph\\\\\\': 12.5, \\\\\\'gust_kph\\\\\\': 20.1}}\"}, {\"url\": \"https://www.timeanddate.com/weather/usa/san-francisco/hourly\", \"content\": \"Sun & Moon. Weather Today Weather Hourly 14 Day Forecast Yesterday/Past Weather Climate (Averages) Currently: 59 \\\\\\\\u00b0F. Passing clouds. (Weather station: San Francisco International Airport, USA). See more current weather.\"}]\\', name=\\'tavily_search_results_json\\', id=\\'37aa1fd9-b232-4a02-bd22-bc5b9b44a22c\\', tool_call_id=\\'toolu_01Y5EK4bw2LqsQXeaUv8iueF\\'), AIMessage(content=\\'Based on the search results, here is a summary of the current weather in San Francisco:\\\\n\\\\nThe weather in San Francisco is currently misty with a temperature of around 53¬∞F (12¬∞C). There is complete cloud cover and moderate winds from the northwest around 5-9 mph (9-14 km/h). Humidity is high at 88%. Visibility is around 3 miles (6.4 km). \\\\n\\\\nThe results provide an hourly forecast as well as current conditions from a couple different weather sources. Let me know if you need any additional details about the San Francisco weather!\\', response_metadata={\\'id\\': \\'msg_01BRX9mrT19nBDdHYtR7wJ92\\', \\'model\\': \\'claude-3-sonnet-20240229\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 920, \\'output_tokens\\': 132}}, id=\\'run-d0325583-3ddc-4432-b2b2-d023eb97660f-0\\', usage_metadata={\\'input_tokens\\': 920, \\'output_tokens\\': 132, \\'total_tokens\\': 1052})]\\nWe can check out the LangSmith trace to make sure it\\'s calling the search tool effectively.\\nStreaming Messages\\u200b\\nWe\\'ve seen how the agent can be called with .invoke to get  a final response. If the agent executes multiple steps, this may take a while. To show intermediate progress, we can stream back messages as they occur.\\nfor step in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]},    stream_mode=\"values\",):    step[\"messages\"][-1].pretty_print()\\n================================\\x1b[1m Human Message \\x1b[0m=================================whats the weather in sf?==================================\\x1b[1m Ai Message \\x1b[0m==================================[{\\'text\\': \\'Okay, let me look up the current weather for San Francisco using a search engine:\\', \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01H1brh5EZpZqtqHBxkosPtN\\', \\'input\\': {\\'query\\': \\'san francisco weather\\'}, \\'name\\': \\'tavily_search_results_json\\', \\'type\\': \\'tool_use\\'}]Tool Calls:  tavily_search_results_json (toolu_01H1brh5EZpZqtqHBxkosPtN) Call ID: toolu_01H1brh5EZpZqtqHBxkosPtN  Args:    query: san francisco weather=================================\\x1b[1m Tool Message \\x1b[0m=================================Name: tavily_search_results_json[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.775, \\'lon\\': -122.4183, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1739994486, \\'localtime\\': \\'2025-02-19 11:48\\'}, \\'current\\': {\\'last_updated_epoch\\': 1739994300, \\'last_updated\\': \\'2025-02-19 11:45\\', \\'temp_c\\': 13.3, \\'temp_f\\': 55.9, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Light rain\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/296.png\\', \\'code\\': 1183}, \\'wind_mph\\': 5.8, \\'wind_kph\\': 9.4, \\'wind_degree\\': 195, \\'wind_dir\\': \\'SSW\\', \\'pressure_mb\\': 1023.0, \\'pressure_in\\': 30.2, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 87, \\'cloud\\': 100, \\'feelslike_c\\': 12.7, \\'feelslike_f\\': 54.8, \\'windchill_c\\': 9.1, \\'windchill_f\\': 48.4, \\'heatindex_c\\': 10.2, \\'heatindex_f\\': 50.3, \\'dewpoint_c\\': 9.8, \\'dewpoint_f\\': 49.7, \\'vis_km\\': 4.0, \\'vis_miles\\': 2.0, \\'uv\\': 1.4, \\'gust_mph\\': 8.9, \\'gust_kph\\': 14.4}}\"}, {\"url\": \"https://world-weather.info/forecast/usa/san_francisco/february-2025/\", \"content\": \"Weather in San Francisco in February 2025 (California) - Detailed Weather Forecast for a Month Weather World Weather in San Francisco Weather in San Francisco in February 2025 San Francisco Weather Forecast for February 2025, is based on previous years\\' statistical data. +59¬∞+50¬∞ +59¬∞+52¬∞ +59¬∞+50¬∞ +61¬∞+52¬∞ +59¬∞+50¬∞ +61¬∞+50¬∞ +61¬∞+52¬∞ +63¬∞+52¬∞ +61¬∞+52¬∞ +61¬∞+50¬∞ +61¬∞+50¬∞ +61¬∞+50¬∞ +59¬∞+50¬∞ +59¬∞+50¬∞ +61¬∞+50¬∞ +61¬∞+52¬∞ +59¬∞+50¬∞ +59¬∞+48¬∞ +57¬∞+48¬∞ +59¬∞+50¬∞ +59¬∞+48¬∞ +59¬∞+50¬∞ +57¬∞+46¬∞ +61¬∞+50¬∞ +61¬∞+50¬∞ +59¬∞+50¬∞ +59¬∞+48¬∞ +59¬∞+50¬∞ Extended weather forecast in San Francisco HourlyWeek10-Day14-Day30-DayYear Weather in large and nearby cities Weather in Washington, D.C.+41¬∞ Sacramento+55¬∞ Pleasanton+55¬∞ Redwood City+55¬∞ San Leandro+55¬∞ San Mateo+54¬∞ San Rafael+52¬∞ San Ramon+52¬∞ South San Francisco+54¬∞ Vallejo+50¬∞ Palo Alto+55¬∞ Pacifica+55¬∞ Berkeley+54¬∞ Castro Valley+55¬∞ Concord+52¬∞ Daly City+54¬∞ Noverd+52¬∞ Sign Hill+54¬∞ world\\'s temperature today day day Temperature units\"}]==================================\\x1b[1m Ai Message \\x1b[0m==================================The search results provide details on the current weather conditions and forecast for San Francisco. Some key details:- It is lightly raining in San Francisco right now, with a temperature around 55¬∞F/13¬∞C. - The forecast for the rest of February 2025 shows daytime highs mostly in the upper 50s to low 60s F, with night lows in the upper 40s to low 50s F. - Typical weather includes some rain, clouds, cool temperatures and breezy conditions.So in summary, as is common for San Francisco in late winter, it is currently cool with light rain showers, and similar mild, unsettled weather is expected over the next couple weeks. Layers and a light jacket would be advisable for being outdoors. Let me know if you need any other details!\\nStreaming tokens\\u200b\\nIn addition to streaming back messages, it is also useful to stream back tokens.\\nWe can do this by specifying stream_mode=\"messages\".\\n::: note\\nBelow we use message.text(), which requires langchain-core>=0.3.37.\\n:::\\nfor step, metadata in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]},    stream_mode=\"messages\",):    if metadata[\"langgraph_node\"] == \"agent\" and (text := step.text()):        print(text, end=\"|\")\\nBase|d on the weather| search| results, here| are the key details| about the weather in| San Francisco:|- The current temperature| in| San Francisco is aroun|d 55|-|56|¬∞F (13|¬∞|C).| Light| rain is occurring with| |100|% clou|d cover. |-| Winds| are aroun|d 5-9| mph from| the south|-southwest.|- The| forecast| for| the rest| of February| 2025 |shows da|ytime highs mostly| in the upper| 50s to| low| 60s¬∞|F,| with overnight lows| in| the upper| 40s to| low| 50s¬∞|F.|-| Overall|, typical| cool| an|d show|ery late| winter weather is| expected in San Francisco| for the remainder| of February,| with a| mix| of rain| and dry| periods|.| Temperatures will be| season|able| for| this| time of year.|So| in summary, San| Francisco is| experiencing light| rain an|d cool| temperatures currently, but| the late| winter forecast| shows typical mil|d and show|ery conditions| pers|isting through the en|d of the| month.| Let| me know if you| need any other| details about| the weather in the| city!|\\nAdding in memory\\u200b\\nAs mentioned earlier, this agent is stateless. This means it does not remember previous interactions. To give it memory we need to pass in a checkpointer. When passing in a checkpointer, we also have to pass in a thread_id when invoking the agent (so it knows which thread/conversation to resume from).\\nfrom langgraph.checkpoint.memory import MemorySavermemory = MemorySaver()API Reference:MemorySaver\\nagent_executor = create_react_agent(model, tools, checkpointer=memory)config = {\"configurable\": {\"thread_id\": \"abc123\"}}\\nfor chunk in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"hi im bob!\")]}, config):    print(chunk)    print(\"----\")\\n{\\'agent\\': {\\'messages\\': [AIMessage(content=\"Hello Bob! It\\'s nice to meet you again.\", response_metadata={\\'id\\': \\'msg_013C1z2ZySagEFwmU1EsysR2\\', \\'model\\': \\'claude-3-sonnet-20240229\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 1162, \\'output_tokens\\': 14}}, id=\\'run-f878acfd-d195-44e8-9166-e2796317e3f8-0\\', usage_metadata={\\'input_tokens\\': 1162, \\'output_tokens\\': 14, \\'total_tokens\\': 1176})]}}----\\nfor chunk in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config):    print(chunk)    print(\"----\")\\n{\\'agent\\': {\\'messages\\': [AIMessage(content=\\'You mentioned your name is Bob when you introduced yourself earlier. So your name is Bob.\\', response_metadata={\\'id\\': \\'msg_01WNwnRNGwGDRw6vRdivt6i1\\', \\'model\\': \\'claude-3-sonnet-20240229\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 1184, \\'output_tokens\\': 21}}, id=\\'run-f5c0b957-8878-405a-9d4b-a7cd38efe81f-0\\', usage_metadata={\\'input_tokens\\': 1184, \\'output_tokens\\': 21, \\'total_tokens\\': 1205})]}}----\\nExample LangSmith trace\\nIf you want to start a new conversation, all you have to do is change the thread_id used\\nconfig = {\"configurable\": {\"thread_id\": \"xyz123\"}}for chunk in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config):    print(chunk)    print(\"----\")\\n{\\'agent\\': {\\'messages\\': [AIMessage(content=\"I\\'m afraid I don\\'t actually know your name. As an AI assistant without personal information about you, I don\\'t have a specific name associated with our conversation.\", response_metadata={\\'id\\': \\'msg_01NoaXNNYZKSoBncPcLkdcbo\\', \\'model\\': \\'claude-3-sonnet-20240229\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 267, \\'output_tokens\\': 36}}, id=\\'run-c9f7df3d-525a-4d8f-bbcf-a5b4a5d2e4b0-0\\', usage_metadata={\\'input_tokens\\': 267, \\'output_tokens\\': 36, \\'total_tokens\\': 303})]}}----\\nConclusion\\u200b\\nThat\\'s a wrap! In this quick start we covered how to create a simple agent.\\nWe\\'ve then shown how to stream back a response - not only with the intermediate steps, but also tokens!\\nWe\\'ve also added in memory so you can have a conversation with them.\\nAgents are a complex topic with lots to learn!\\nFor more information on Agents, please check out the LangGraph documentation. This has it\\'s own set of concepts, tutorials, and how-to guides.Edit this pageWas this page helpful?PreviousBuild an Extraction ChainNextTaggingEnd-to-end agentSetupJupyter NotebookInstallationLangSmithTavilyDefine toolsUsing Language ModelsCreate the agentRun the agentStreaming MessagesStreaming tokensAdding in memoryConclusionCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright ¬© 2025 LangChain, Inc.\\n\\n')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eab5c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1281e36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='Build an Agent | ü¶úÔ∏èüîó LangChain'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='Skip to main contentWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith.  Join our team!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1üí¨SearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content=\"ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain's stateHow to construct filters for query analysisHow to configure runtime chain internalsHow deal with high cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one\"),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse text from message objectsHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with langchainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystemü¶úüõ†Ô∏è LangSmithü¶úüï∏Ô∏è LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='callingToolsTracingVector storesWhy LangChain?Ecosystemü¶úüõ†Ô∏è LangSmithü¶úüï∏Ô∏è LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyTutorialsBuild an AgentOn this pageBuild an'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyTutorialsBuild an AgentOn this pageBuild an Agent'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content=\"By themselves, language models can't take actions - they just output text.\\nA big use case for LangChain is creating agents.\\nAgents are systems that use LLMs as reasoning engines to determine which actions to take and the inputs necessary to perform the action.\\nAfter executing actions, the results can be fed back into the LLM to determine whether more actions are needed, or whether it is okay to finish. This is often achieved via tool-calling.\\nIn this tutorial we will build an agent that can interact with a search engine. You will be able to ask this agent questions, watch it call the search tool, and have conversations with it.\\nEnd-to-end agent\\u200b\\nThe code snippet below represents a fully functional agent that uses an LLM to decide which tools to use. It is equipped with a generic search tool. It has conversational memory - meaning that it can be used as a multi-turn chatbot.\"),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='In the rest of the guide, we will walk through the individual components and what each part does - but if you want to just grab some code and get started, feel free to use this!\\n# Import relevant functionalityfrom langchain_anthropic import ChatAnthropicfrom langchain_community.tools.tavily_search import TavilySearchResultsfrom langchain_core.messages import HumanMessagefrom langgraph.checkpoint.memory import MemorySaverfrom langgraph.prebuilt import create_react_agent# Create the agentmemory = MemorySaver()model = ChatAnthropic(model_name=\"claude-3-sonnet-20240229\")search = TavilySearchResults(max_results=2)tools = [search]agent_executor = create_react_agent(model, tools, checkpointer=memory)API Reference:ChatAnthropic | TavilySearchResults | HumanMessage | MemorySaver | create_react_agent'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='# Use the agentconfig = {\"configurable\": {\"thread_id\": \"abc123\"}}for step in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"hi im bob! and i live in sf\")]},    config,    stream_mode=\"values\",):    step[\"messages\"][-1].pretty_print()\\n================================\\x1b[1m Human Message \\x1b[0m=================================hi im bob! and i live in sf==================================\\x1b[1m Ai Message \\x1b[0m==================================Hello Bob! Since you didn\\'t ask a specific question, I don\\'t need to use any tools right now. I\\'m an AI assistant created by Anthropic to be helpful, honest, and harmless. Feel free to ask me anything and I\\'ll do my best to provide a useful response or look up information using my capabilities.\\nfor step in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"whats the weather where I live?\")]},    config,    stream_mode=\"values\",):    step[\"messages\"][-1].pretty_print()'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='================================\\x1b[1m Human Message \\x1b[0m=================================whats the weather where I live?==================================\\x1b[1m Ai Message \\x1b[0m==================================[{\\'text\\': \\'To get the current weather for your location in San Francisco, I can use the tavily_search_results_json tool:\\', \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01AKa2MErG1CU3zRiGsvpBud\\', \\'input\\': {\\'query\\': \\'san francisco weather\\'}, \\'name\\': \\'tavily_search_results_json\\', \\'type\\': \\'tool_use\\'}]Tool Calls:  tavily_search_results_json (toolu_01AKa2MErG1CU3zRiGsvpBud) Call ID: toolu_01AKa2MErG1CU3zRiGsvpBud  Args:    query: san francisco weather=================================\\x1b[1m Tool Message \\x1b[0m=================================Name: tavily_search_results_json[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.775, \\'lon\\': -122.4183, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\':'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='\"content\": \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.775, \\'lon\\': -122.4183, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1739994486, \\'localtime\\': \\'2025-02-19 11:48\\'}, \\'current\\': {\\'last_updated_epoch\\': 1739994300, \\'last_updated\\': \\'2025-02-19 11:45\\', \\'temp_c\\': 13.3, \\'temp_f\\': 55.9, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Light rain\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/296.png\\', \\'code\\': 1183}, \\'wind_mph\\': 5.8, \\'wind_kph\\': 9.4, \\'wind_degree\\': 195, \\'wind_dir\\': \\'SSW\\', \\'pressure_mb\\': 1023.0, \\'pressure_in\\': 30.2, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 87, \\'cloud\\': 100, \\'feelslike_c\\': 12.7, \\'feelslike_f\\': 54.8, \\'windchill_c\\': 9.1, \\'windchill_f\\': 48.4, \\'heatindex_c\\': 10.2, \\'heatindex_f\\': 50.3, \\'dewpoint_c\\': 9.8, \\'dewpoint_f\\': 49.7, \\'vis_km\\': 4.0, \\'vis_miles\\': 2.0, \\'uv\\': 1.4, \\'gust_mph\\': 8.9, \\'gust_kph\\': 14.4}}\"}, {\"url\": \"https://world-weather.info/forecast/usa/san_francisco/february-2025/\",'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='9.8, \\'dewpoint_f\\': 49.7, \\'vis_km\\': 4.0, \\'vis_miles\\': 2.0, \\'uv\\': 1.4, \\'gust_mph\\': 8.9, \\'gust_kph\\': 14.4}}\"}, {\"url\": \"https://world-weather.info/forecast/usa/san_francisco/february-2025/\", \"content\": \"Weather in San Francisco in February 2025 (California) - Detailed Weather Forecast for a Month Weather World Weather in San Francisco Weather in San Francisco in February 2025 San Francisco Weather Forecast for February 2025, is based on previous years\\' statistical data. +59¬∞+50¬∞ +59¬∞+52¬∞ +59¬∞+50¬∞ +61¬∞+52¬∞ +59¬∞+50¬∞ +61¬∞+50¬∞ +61¬∞+52¬∞ +63¬∞+52¬∞ +61¬∞+52¬∞ +61¬∞+50¬∞ +61¬∞+50¬∞ +61¬∞+50¬∞ +59¬∞+50¬∞ +59¬∞+50¬∞ +61¬∞+50¬∞ +61¬∞+52¬∞ +59¬∞+50¬∞ +59¬∞+48¬∞ +57¬∞+48¬∞ +59¬∞+50¬∞ +59¬∞+48¬∞ +59¬∞+50¬∞ +57¬∞+46¬∞ +61¬∞+50¬∞ +61¬∞+50¬∞ +59¬∞+50¬∞ +59¬∞+48¬∞ +59¬∞+50¬∞ Extended weather forecast in San Francisco HourlyWeek10-Day14-Day30-DayYear Weather in large and nearby cities Weather in Washington, D.C.+41¬∞ Sacramento+55¬∞ Pleasanton+55¬∞ Redwood City+55¬∞ San Leandro+55¬∞ San Mateo+54¬∞ San Rafael+52¬∞ San Ramon+52¬∞ South San Francisco+54¬∞'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='Weather in large and nearby cities Weather in Washington, D.C.+41¬∞ Sacramento+55¬∞ Pleasanton+55¬∞ Redwood City+55¬∞ San Leandro+55¬∞ San Mateo+54¬∞ San Rafael+52¬∞ San Ramon+52¬∞ South San Francisco+54¬∞ Vallejo+50¬∞ Palo Alto+55¬∞ Pacifica+55¬∞ Berkeley+54¬∞ Castro Valley+55¬∞ Concord+52¬∞ Daly City+54¬∞ Noverd+52¬∞ Sign Hill+54¬∞ world\\'s temperature today day day Temperature units\"}]==================================\\x1b[1m Ai Message \\x1b[0m==================================The search results provide the current weather conditions and forecast for San Francisco. According to the data from WeatherAPI, the current temperature in San Francisco is around 55¬∞F (13¬∞C) with light rain and winds around 6 mph. The extended forecast shows temperatures ranging from the upper 40s to low 60s Fahrenheit over the next few weeks.So in summary, it\\'s a cool, rainy day currently in San Francisco where you live, Bob. Let me know if you need any other details about the weather there!'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='Setup\\u200b\\nJupyter Notebook\\u200b\\nThis guide (and most of the other guides in the documentation) uses Jupyter notebooks and assumes the reader is as well. Jupyter notebooks are perfect interactive environments for learning how to work with LLM systems because oftentimes things can go wrong (unexpected output, API down, etc), and observing these cases is a great way to better understand building with LLMs.\\nThis and other tutorials are perhaps most conveniently run in a Jupyter notebook. See here for instructions on how to install.\\nInstallation\\u200b\\nTo install LangChain run:\\n%pip install -U langchain-community langgraph langchain-anthropic tavily-python langgraph-checkpoint-sqlite\\nFor more details, see our Installation guide.\\nLangSmith\\u200b\\nMany of the applications you build with LangChain will contain multiple steps with multiple invocations of LLM calls.\\nAs these applications get more and more complex, it becomes crucial to be able to inspect what exactly is going on inside your chain or agent.'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='As these applications get more and more complex, it becomes crucial to be able to inspect what exactly is going on inside your chain or agent.\\nThe best way to do this is with LangSmith.\\nAfter you sign up at the link above, make sure to set your environment variables to start logging traces:\\nexport LANGSMITH_TRACING=\"true\"export LANGSMITH_API_KEY=\"...\"\\nOr, if in a notebook, you can set them with:\\nimport getpassimport osos.environ[\"LANGSMITH_TRACING\"] = \"true\"os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()\\nTavily\\u200b\\nWe will be using Tavily (a search engine) as a tool.\\nIn order to use it, you will need to get and set an API key:\\nexport TAVILY_API_KEY=\"...\"\\nOr, if in a notebook, you can set it with:\\nimport getpassimport osos.environ[\"TAVILY_API_KEY\"] = getpass.getpass()\\nDefine tools\\u200b\\nWe first need to create the tools we want to use. Our main tool of choice will be Tavily - a search engine. We have a built-in tool in LangChain to easily use Tavily search engine as tool.'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='We first need to create the tools we want to use. Our main tool of choice will be Tavily - a search engine. We have a built-in tool in LangChain to easily use Tavily search engine as tool.\\nfrom langchain_community.tools.tavily_search import TavilySearchResultssearch = TavilySearchResults(max_results=2)search_results = search.invoke(\"what is the weather in SF\")print(search_results)# If we want, we can create other tools.# Once we have all the tools we want, we can put them in a list that we will reference later.tools = [search]API Reference:TavilySearchResults'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.775, \\'lon\\': -122.4183, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1739993250, \\'localtime\\': \\'2025-02-19 11:27\\'}, \\'current\\': {\\'last_updated_epoch\\': 1739992500, \\'last_updated\\': \\'2025-02-19 11:15\\', \\'temp_c\\': 13.3, \\'temp_f\\': 55.9, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Light rain\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/296.png\\', \\'code\\': 1183}, \\'wind_mph\\': 5.8, \\'wind_kph\\': 9.4, \\'wind_degree\\': 195, \\'wind_dir\\': \\'SSW\\', \\'pressure_mb\\': 1023.0, \\'pressure_in\\': 30.2, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 87, \\'cloud\\': 100, \\'feelslike_c\\': 12.7, \\'feelslike_f\\': 54.8, \\'windchill_c\\': 9.1, \\'windchill_f\\': 48.4, \\'heatindex_c\\': 10.2, \\'heatindex_f\\': 50.3, \\'dewpoint_c\\': 9.8, \\'dewpoint_f\\': 49.7, \\'vis_km\\': 4.0, \\'vis_miles\\': 2.0, \\'uv\\': 1.4, \\'gust_mph\\': 8.9, \\'gust_kph\\': 14.4}}\"}, {\\'url\\':'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='9.1, \\'windchill_f\\': 48.4, \\'heatindex_c\\': 10.2, \\'heatindex_f\\': 50.3, \\'dewpoint_c\\': 9.8, \\'dewpoint_f\\': 49.7, \\'vis_km\\': 4.0, \\'vis_miles\\': 2.0, \\'uv\\': 1.4, \\'gust_mph\\': 8.9, \\'gust_kph\\': 14.4}}\"}, {\\'url\\': \\'https://weathershogun.com/weather/usa/ca/san-francisco/480/february/2025-02-19\\', \\'content\\': \\'San Francisco, California Weather: Wednesday, February 19, 2025. Cloudy weather, overcast skies with clouds. Day 61¬∞. Night 43¬∞.\\'}]'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content=\"Using Language Models\\u200b\\nNext, let's learn how to use a language model to call tools. LangChain supports many different language models that you can use interchangably - select the one you want to use below!\"),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='Select chat model:Google Gemini‚ñæOpenAIAnthropicAzureGoogle GeminiGoogle VertexAWSGroqCohereNVIDIAFireworks AIMistral AITogether AIIBM watsonxDatabricksxAIPerplexitypip install -qU \"langchain[google-genai]\"import getpassimport osif not os.environ.get(\"GOOGLE_API_KEY\"):  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")from langchain.chat_models import init_chat_modelmodel = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")\\nYou can call the language model by passing in a list of messages. By default, the response is a content string.\\nfrom langchain_core.messages import HumanMessageresponse = model.invoke([HumanMessage(content=\"hi!\")])response.contentAPI Reference:HumanMessage\\n\\'Hi there!\\'\\nWe can now see what it is like to enable this model to do tool calling. In order to enable that we use .bind_tools to give the language model knowledge of these tools\\nmodel_with_tools = model.bind_tools(tools)'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='model_with_tools = model.bind_tools(tools)\\nWe can now call the model. Let\\'s first call it with a normal message, and see how it responds. We can look at both the content field as well as the tool_calls field.\\nresponse = model_with_tools.invoke([HumanMessage(content=\"Hi!\")])print(f\"ContentString: {response.content}\")print(f\"ToolCalls: {response.tool_calls}\")\\nContentString: Hello!ToolCalls: []\\nNow, let\\'s try calling it with some input that would expect a tool to be called.\\nresponse = model_with_tools.invoke([HumanMessage(content=\"What\\'s the weather in SF?\")])print(f\"ContentString: {response.content}\")print(f\"ToolCalls: {response.tool_calls}\")\\nContentString: ToolCalls: [{\\'name\\': \\'tavily_search_results_json\\', \\'args\\': {\\'query\\': \\'weather san francisco\\'}, \\'id\\': \\'toolu_01VTP7DUvSfgtYxsq9x4EwMp\\'}]\\nWe can see that there\\'s now no text content, but there is a tool call! It wants us to call the Tavily Search tool.'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content=\"We can see that there's now no text content, but there is a tool call! It wants us to call the Tavily Search tool.\\nThis isn't calling that tool yet - it's just telling us to. In order to actually call it, we'll want to create our agent.\\nCreate the agent\\u200b\\nNow that we have defined the tools and the LLM, we can create the agent. We will be using LangGraph to construct the agent.\\nCurrently, we are using a high level interface to construct the agent, but the nice thing about LangGraph is that this high-level interface is backed by a low-level, highly controllable API in case you want to modify the agent logic.\\nNow, we can initialize the agent with the LLM and the tools.\\nNote that we are passing in the model, not model_with_tools. That is because create_react_agent will call .bind_tools for us under the hood.\\nfrom langgraph.prebuilt import create_react_agentagent_executor = create_react_agent(model, tools)API Reference:create_react_agent\\nRun the agent\\u200b\"),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='from langgraph.prebuilt import create_react_agentagent_executor = create_react_agent(model, tools)API Reference:create_react_agent\\nRun the agent\\u200b\\nWe can now run the agent with a few queries! Note that for now, these are all stateless queries (it won\\'t remember previous interactions). Note that the agent will return the final state at the end of the interaction (which includes any inputs, we will see later on how to get only the outputs).\\nFirst up, let\\'s see how it responds when there\\'s no need to call a tool:\\nresponse = agent_executor.invoke({\"messages\": [HumanMessage(content=\"hi!\")]})response[\"messages\"]'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='First up, let\\'s see how it responds when there\\'s no need to call a tool:\\nresponse = agent_executor.invoke({\"messages\": [HumanMessage(content=\"hi!\")]})response[\"messages\"]\\n[HumanMessage(content=\\'hi!\\', id=\\'a820fcc5-9b87-457a-9af0-f21768143ee3\\'), AIMessage(content=\\'Hello!\\', response_metadata={\\'id\\': \\'msg_01VbC493X1VEDyusgttiEr1z\\', \\'model\\': \\'claude-3-sonnet-20240229\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 264, \\'output_tokens\\': 5}}, id=\\'run-0e0ddae8-a85b-4bd6-947c-c36c857a4698-0\\', usage_metadata={\\'input_tokens\\': 264, \\'output_tokens\\': 5, \\'total_tokens\\': 269})]\\nIn order to see exactly what is happening under the hood (and to make sure it\\'s not calling a tool) we can take a look at the LangSmith trace\\nLet\\'s now try it out on an example where it should be invoking the tool\\nresponse = agent_executor.invoke(    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]})response[\"messages\"]'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='[HumanMessage(content=\\'whats the weather in sf?\\', id=\\'1d6c96bb-4ddb-415c-a579-a07d5264de0d\\'), AIMessage(content=[{\\'id\\': \\'toolu_01Y5EK4bw2LqsQXeaUv8iueF\\', \\'input\\': {\\'query\\': \\'weather in san francisco\\'}, \\'name\\': \\'tavily_search_results_json\\', \\'type\\': \\'tool_use\\'}], response_metadata={\\'id\\': \\'msg_0132wQUcEduJ8UKVVVqwJzM4\\', \\'model\\': \\'claude-3-sonnet-20240229\\', \\'stop_reason\\': \\'tool_use\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 269, \\'output_tokens\\': 61}}, id=\\'run-26d5e5e8-d4fd-46d2-a197-87b95b10e823-0\\', tool_calls=[{\\'name\\': \\'tavily_search_results_json\\', \\'args\\': {\\'query\\': \\'weather in san francisco\\'}, \\'id\\': \\'toolu_01Y5EK4bw2LqsQXeaUv8iueF\\'}], usage_metadata={\\'input_tokens\\': 269, \\'output_tokens\\': 61, \\'total_tokens\\': 330}), ToolMessage(content=\\'[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\\\\\'location\\\\\\': {\\\\\\'name\\\\\\': \\\\\\'San Francisco\\\\\\', \\\\\\'region\\\\\\': \\\\\\'California\\\\\\', \\\\\\'country\\\\\\': \\\\\\'United States of America\\\\\\', \\\\\\'lat\\\\\\': 37.78, \\\\\\'lon\\\\\\': -122.42, \\\\\\'tz_id\\\\\\': \\\\\\'America/Los_Angeles\\\\\\','),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='\"content\": \"{\\\\\\'location\\\\\\': {\\\\\\'name\\\\\\': \\\\\\'San Francisco\\\\\\', \\\\\\'region\\\\\\': \\\\\\'California\\\\\\', \\\\\\'country\\\\\\': \\\\\\'United States of America\\\\\\', \\\\\\'lat\\\\\\': 37.78, \\\\\\'lon\\\\\\': -122.42, \\\\\\'tz_id\\\\\\': \\\\\\'America/Los_Angeles\\\\\\', \\\\\\'localtime_epoch\\\\\\': 1717238703, \\\\\\'localtime\\\\\\': \\\\\\'2024-06-01 3:45\\\\\\'}, \\\\\\'current\\\\\\': {\\\\\\'last_updated_epoch\\\\\\': 1717237800, \\\\\\'last_updated\\\\\\': \\\\\\'2024-06-01 03:30\\\\\\', \\\\\\'temp_c\\\\\\': 12.0, \\\\\\'temp_f\\\\\\': 53.6, \\\\\\'is_day\\\\\\': 0, \\\\\\'condition\\\\\\': {\\\\\\'text\\\\\\': \\\\\\'Mist\\\\\\', \\\\\\'icon\\\\\\': \\\\\\'//cdn.weatherapi.com/weather/64x64/night/143.png\\\\\\', \\\\\\'code\\\\\\': 1030}, \\\\\\'wind_mph\\\\\\': 5.6, \\\\\\'wind_kph\\\\\\': 9.0, \\\\\\'wind_degree\\\\\\': 310, \\\\\\'wind_dir\\\\\\': \\\\\\'NW\\\\\\', \\\\\\'pressure_mb\\\\\\': 1013.0, \\\\\\'pressure_in\\\\\\': 29.92, \\\\\\'precip_mm\\\\\\': 0.0, \\\\\\'precip_in\\\\\\': 0.0, \\\\\\'humidity\\\\\\': 88, \\\\\\'cloud\\\\\\': 100, \\\\\\'feelslike_c\\\\\\': 10.5, \\\\\\'feelslike_f\\\\\\': 50.8, \\\\\\'windchill_c\\\\\\': 9.3, \\\\\\'windchill_f\\\\\\': 48.7, \\\\\\'heatindex_c\\\\\\': 11.1, \\\\\\'heatindex_f\\\\\\': 51.9, \\\\\\'dewpoint_c\\\\\\': 8.8, \\\\\\'dewpoint_f\\\\\\': 47.8, \\\\\\'vis_km\\\\\\': 6.4, \\\\\\'vis_miles\\\\\\': 3.0, \\\\\\'uv\\\\\\': 1.0, \\\\\\'gust_mph\\\\\\': 12.5, \\\\\\'gust_kph\\\\\\':'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='\\\\\\'windchill_f\\\\\\': 48.7, \\\\\\'heatindex_c\\\\\\': 11.1, \\\\\\'heatindex_f\\\\\\': 51.9, \\\\\\'dewpoint_c\\\\\\': 8.8, \\\\\\'dewpoint_f\\\\\\': 47.8, \\\\\\'vis_km\\\\\\': 6.4, \\\\\\'vis_miles\\\\\\': 3.0, \\\\\\'uv\\\\\\': 1.0, \\\\\\'gust_mph\\\\\\': 12.5, \\\\\\'gust_kph\\\\\\': 20.1}}\"}, {\"url\": \"https://www.timeanddate.com/weather/usa/san-francisco/hourly\", \"content\": \"Sun & Moon. Weather Today Weather Hourly 14 Day Forecast Yesterday/Past Weather Climate (Averages) Currently: 59 \\\\\\\\u00b0F. Passing clouds. (Weather station: San Francisco International Airport, USA). See more current weather.\"}]\\', name=\\'tavily_search_results_json\\', id=\\'37aa1fd9-b232-4a02-bd22-bc5b9b44a22c\\', tool_call_id=\\'toolu_01Y5EK4bw2LqsQXeaUv8iueF\\'), AIMessage(content=\\'Based on the search results, here is a summary of the current weather in San Francisco:\\\\n\\\\nThe weather in San Francisco is currently misty with a temperature of around 53¬∞F (12¬∞C). There is complete cloud cover and moderate winds from the northwest around 5-9 mph (9-14 km/h). Humidity is high at 88%. Visibility is around 3 miles'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content=\"misty with a temperature of around 53¬∞F (12¬∞C). There is complete cloud cover and moderate winds from the northwest around 5-9 mph (9-14 km/h). Humidity is high at 88%. Visibility is around 3 miles (6.4 km). \\\\n\\\\nThe results provide an hourly forecast as well as current conditions from a couple different weather sources. Let me know if you need any additional details about the San Francisco weather!', response_metadata={'id': 'msg_01BRX9mrT19nBDdHYtR7wJ92', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 920, 'output_tokens': 132}}, id='run-d0325583-3ddc-4432-b2b2-d023eb97660f-0', usage_metadata={'input_tokens': 920, 'output_tokens': 132, 'total_tokens': 1052})]\"),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='We can check out the LangSmith trace to make sure it\\'s calling the search tool effectively.\\nStreaming Messages\\u200b\\nWe\\'ve seen how the agent can be called with .invoke to get  a final response. If the agent executes multiple steps, this may take a while. To show intermediate progress, we can stream back messages as they occur.\\nfor step in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]},    stream_mode=\"values\",):    step[\"messages\"][-1].pretty_print()'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='================================\\x1b[1m Human Message \\x1b[0m=================================whats the weather in sf?==================================\\x1b[1m Ai Message \\x1b[0m==================================[{\\'text\\': \\'Okay, let me look up the current weather for San Francisco using a search engine:\\', \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01H1brh5EZpZqtqHBxkosPtN\\', \\'input\\': {\\'query\\': \\'san francisco weather\\'}, \\'name\\': \\'tavily_search_results_json\\', \\'type\\': \\'tool_use\\'}]Tool Calls:  tavily_search_results_json (toolu_01H1brh5EZpZqtqHBxkosPtN) Call ID: toolu_01H1brh5EZpZqtqHBxkosPtN  Args:    query: san francisco weather=================================\\x1b[1m Tool Message \\x1b[0m=================================Name: tavily_search_results_json[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.775, \\'lon\\': -122.4183, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1739994486, \\'localtime\\':'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='{\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.775, \\'lon\\': -122.4183, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1739994486, \\'localtime\\': \\'2025-02-19 11:48\\'}, \\'current\\': {\\'last_updated_epoch\\': 1739994300, \\'last_updated\\': \\'2025-02-19 11:45\\', \\'temp_c\\': 13.3, \\'temp_f\\': 55.9, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Light rain\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/296.png\\', \\'code\\': 1183}, \\'wind_mph\\': 5.8, \\'wind_kph\\': 9.4, \\'wind_degree\\': 195, \\'wind_dir\\': \\'SSW\\', \\'pressure_mb\\': 1023.0, \\'pressure_in\\': 30.2, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 87, \\'cloud\\': 100, \\'feelslike_c\\': 12.7, \\'feelslike_f\\': 54.8, \\'windchill_c\\': 9.1, \\'windchill_f\\': 48.4, \\'heatindex_c\\': 10.2, \\'heatindex_f\\': 50.3, \\'dewpoint_c\\': 9.8, \\'dewpoint_f\\': 49.7, \\'vis_km\\': 4.0, \\'vis_miles\\': 2.0, \\'uv\\': 1.4, \\'gust_mph\\': 8.9, \\'gust_kph\\': 14.4}}\"}, {\"url\": \"https://world-weather.info/forecast/usa/san_francisco/february-2025/\", \"content\": \"Weather in San'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='49.7, \\'vis_km\\': 4.0, \\'vis_miles\\': 2.0, \\'uv\\': 1.4, \\'gust_mph\\': 8.9, \\'gust_kph\\': 14.4}}\"}, {\"url\": \"https://world-weather.info/forecast/usa/san_francisco/february-2025/\", \"content\": \"Weather in San Francisco in February 2025 (California) - Detailed Weather Forecast for a Month Weather World Weather in San Francisco Weather in San Francisco in February 2025 San Francisco Weather Forecast for February 2025, is based on previous years\\' statistical data. +59¬∞+50¬∞ +59¬∞+52¬∞ +59¬∞+50¬∞ +61¬∞+52¬∞ +59¬∞+50¬∞ +61¬∞+50¬∞ +61¬∞+52¬∞ +63¬∞+52¬∞ +61¬∞+52¬∞ +61¬∞+50¬∞ +61¬∞+50¬∞ +61¬∞+50¬∞ +59¬∞+50¬∞ +59¬∞+50¬∞ +61¬∞+50¬∞ +61¬∞+52¬∞ +59¬∞+50¬∞ +59¬∞+48¬∞ +57¬∞+48¬∞ +59¬∞+50¬∞ +59¬∞+48¬∞ +59¬∞+50¬∞ +57¬∞+46¬∞ +61¬∞+50¬∞ +61¬∞+50¬∞ +59¬∞+50¬∞ +59¬∞+48¬∞ +59¬∞+50¬∞ Extended weather forecast in San Francisco HourlyWeek10-Day14-Day30-DayYear Weather in large and nearby cities Weather in Washington, D.C.+41¬∞ Sacramento+55¬∞ Pleasanton+55¬∞ Redwood City+55¬∞ San Leandro+55¬∞ San Mateo+54¬∞ San Rafael+52¬∞ San Ramon+52¬∞ South San Francisco+54¬∞ Vallejo+50¬∞ Palo'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='and nearby cities Weather in Washington, D.C.+41¬∞ Sacramento+55¬∞ Pleasanton+55¬∞ Redwood City+55¬∞ San Leandro+55¬∞ San Mateo+54¬∞ San Rafael+52¬∞ San Ramon+52¬∞ South San Francisco+54¬∞ Vallejo+50¬∞ Palo Alto+55¬∞ Pacifica+55¬∞ Berkeley+54¬∞ Castro Valley+55¬∞ Concord+52¬∞ Daly City+54¬∞ Noverd+52¬∞ Sign Hill+54¬∞ world\\'s temperature today day day Temperature units\"}]==================================\\x1b[1m Ai Message \\x1b[0m==================================The search results provide details on the current weather conditions and forecast for San Francisco. Some key details:- It is lightly raining in San Francisco right now, with a temperature around 55¬∞F/13¬∞C. - The forecast for the rest of February 2025 shows daytime highs mostly in the upper 50s to low 60s F, with night lows in the upper 40s to low 50s F. - Typical weather includes some rain, clouds, cool temperatures and breezy conditions.So in summary, as is common for San Francisco in late winter, it is currently cool with light rain showers, and'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='- Typical weather includes some rain, clouds, cool temperatures and breezy conditions.So in summary, as is common for San Francisco in late winter, it is currently cool with light rain showers, and similar mild, unsettled weather is expected over the next couple weeks. Layers and a light jacket would be advisable for being outdoors. Let me know if you need any other details!'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='Streaming tokens\\u200b\\nIn addition to streaming back messages, it is also useful to stream back tokens.\\nWe can do this by specifying stream_mode=\"messages\".\\n::: note\\nBelow we use message.text(), which requires langchain-core>=0.3.37.\\n:::\\nfor step, metadata in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]},    stream_mode=\"messages\",):    if metadata[\"langgraph_node\"] == \"agent\" and (text := step.text()):        print(text, end=\"|\")'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='Base|d on the weather| search| results, here| are the key details| about the weather in| San Francisco:|- The current temperature| in| San Francisco is aroun|d 55|-|56|¬∞F (13|¬∞|C).| Light| rain is occurring with| |100|% clou|d cover. |-| Winds| are aroun|d 5-9| mph from| the south|-southwest.|- The| forecast| for| the rest| of February| 2025 |shows da|ytime highs mostly| in the upper| 50s to| low| 60s¬∞|F,| with overnight lows| in| the upper| 40s to| low| 50s¬∞|F.|-| Overall|, typical| cool| an|d show|ery late| winter weather is| expected in San Francisco| for the remainder| of February,| with a| mix| of rain| and dry| periods|.| Temperatures will be| season|able| for| this| time of year.|So| in summary, San| Francisco is| experiencing light| rain an|d cool| temperatures currently, but| the late| winter forecast| shows typical mil|d and show|ery conditions| pers|isting through the en|d of the| month.| Let| me know if you| need any other| details about| the weather in the| city!|'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='Adding in memory\\u200b\\nAs mentioned earlier, this agent is stateless. This means it does not remember previous interactions. To give it memory we need to pass in a checkpointer. When passing in a checkpointer, we also have to pass in a thread_id when invoking the agent (so it knows which thread/conversation to resume from).\\nfrom langgraph.checkpoint.memory import MemorySavermemory = MemorySaver()API Reference:MemorySaver\\nagent_executor = create_react_agent(model, tools, checkpointer=memory)config = {\"configurable\": {\"thread_id\": \"abc123\"}}\\nfor chunk in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"hi im bob!\")]}, config):    print(chunk)    print(\"----\")'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='for chunk in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"hi im bob!\")]}, config):    print(chunk)    print(\"----\")\\n{\\'agent\\': {\\'messages\\': [AIMessage(content=\"Hello Bob! It\\'s nice to meet you again.\", response_metadata={\\'id\\': \\'msg_013C1z2ZySagEFwmU1EsysR2\\', \\'model\\': \\'claude-3-sonnet-20240229\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 1162, \\'output_tokens\\': 14}}, id=\\'run-f878acfd-d195-44e8-9166-e2796317e3f8-0\\', usage_metadata={\\'input_tokens\\': 1162, \\'output_tokens\\': 14, \\'total_tokens\\': 1176})]}}----\\nfor chunk in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config):    print(chunk)    print(\"----\")'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='for chunk in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config):    print(chunk)    print(\"----\")\\n{\\'agent\\': {\\'messages\\': [AIMessage(content=\\'You mentioned your name is Bob when you introduced yourself earlier. So your name is Bob.\\', response_metadata={\\'id\\': \\'msg_01WNwnRNGwGDRw6vRdivt6i1\\', \\'model\\': \\'claude-3-sonnet-20240229\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 1184, \\'output_tokens\\': 21}}, id=\\'run-f5c0b957-8878-405a-9d4b-a7cd38efe81f-0\\', usage_metadata={\\'input_tokens\\': 1184, \\'output_tokens\\': 21, \\'total_tokens\\': 1205})]}}----\\nExample LangSmith trace\\nIf you want to start a new conversation, all you have to do is change the thread_id used\\nconfig = {\"configurable\": {\"thread_id\": \"xyz123\"}}for chunk in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config):    print(chunk)    print(\"----\")'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='config = {\"configurable\": {\"thread_id\": \"xyz123\"}}for chunk in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config):    print(chunk)    print(\"----\")\\n{\\'agent\\': {\\'messages\\': [AIMessage(content=\"I\\'m afraid I don\\'t actually know your name. As an AI assistant without personal information about you, I don\\'t have a specific name associated with our conversation.\", response_metadata={\\'id\\': \\'msg_01NoaXNNYZKSoBncPcLkdcbo\\', \\'model\\': \\'claude-3-sonnet-20240229\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 267, \\'output_tokens\\': 36}}, id=\\'run-c9f7df3d-525a-4d8f-bbcf-a5b4a5d2e4b0-0\\', usage_metadata={\\'input_tokens\\': 267, \\'output_tokens\\': 36, \\'total_tokens\\': 303})]}}----\\nConclusion\\u200b\\nThat\\'s a wrap! In this quick start we covered how to create a simple agent.\\nWe\\'ve then shown how to stream back a response - not only with the intermediate steps, but also tokens!\\nWe\\'ve also added in memory so you can have a conversation with them.'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content=\"We've then shown how to stream back a response - not only with the intermediate steps, but also tokens!\\nWe've also added in memory so you can have a conversation with them.\\nAgents are a complex topic with lots to learn!\\nFor more information on Agents, please check out the LangGraph documentation. This has it's own set of concepts, tutorials, and how-to guides.Edit this pageWas this page helpful?PreviousBuild an Extraction ChainNextTaggingEnd-to-end agentSetupJupyter NotebookInstallationLangSmithTavilyDefine toolsUsing Language ModelsCreate the agentRun the agentStreaming MessagesStreaming tokensAdding in memoryConclusionCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright ¬© 2025 LangChain, Inc.\")]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dce9f6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OllamaEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x000002D6FF762C80>, search_kwargs={})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=texts,\n",
    "    embedding=embeddings,\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fed6b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are a helpful assistant that answers questions about LangChain. \"\n",
    "    \"You have access to the following documents:\"\n",
    "    \"\\n{context}\\n\"\n",
    "    \"Use the information in the documents to answer the user's question. \"\n",
    "    \"\\n\\n\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f13d1f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02d9ac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm,prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "490068f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What are Langchain components?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8b109ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the provided documentation, LangChain components include:\\n\\n1. Language Models (LLMs): LangChain supports multiple language models that can be used interchangeably.\\n2. Agents: Agents are systems that use LLMs as reasoning engines to determine which actions to take and the inputs necessary to perform the action.\\n3. Tool-Calling: Agents can call tools to execute actions and receive results, which can then be fed back into the LLM to determine whether more actions are needed or whether it is okay to finish.\\n\\nAdditionally, the documentation mentions the following components:\\n\\n4. Configurable components: These allow users to customize the behavior of their LangChain applications.\\n5. LangSmith: This is a utility for inspecting the inner workings of LangChain applications, which can be useful for debugging complex applications.\\n\\nIt\\'s worth noting that the provided code snippet showcases an \"end-to-end agent\" that uses an LLM to decide which tools to use, and it has conversational memory, allowing it to be used as a multi-turn chatbot.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf374fe",
   "metadata": {},
   "source": [
    "# Chat History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98d57163",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever# retriever knowledge of previous questions history\n",
    "from langchain_core.prompts import MessagesPlaceholder # to use in the prompt for a variable that will hold the history of previous questions\n",
    "\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question\"\n",
    "    \"which might be of reference context in chat history,\"\n",
    "    \"contextualize the question to be more specific.\"\n",
    "    \"without chat history, do not answer the question\"\n",
    "    \"just reformalize it if needed and otherwise return the question as is.\"\n",
    ")\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"), # Placeholder for chat history\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "844910bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_aware_retriever = create_history_aware_retriever(retriever,llm,contextualize_q_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee7b7d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBranch(branches=[(RunnableLambda(lambda x: not x.get('chat_history', False)), RunnableLambda(lambda x: x['input'])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002D6E63F3E20>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002D6E642D2D0>, model_name='Llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')))], default=ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000002D6E5E789D0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Given a chat history and the latest user questionwhich might be of reference context in chat history,contextualize the question to be more specific.without chat history, do not answer the questionjust reformalize it if needed and otherwise return the question as is.'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| VectorStoreRetriever(tags=['Chroma', 'OllamaEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x000002D6FF762C80>, search_kwargs={})\n",
       "| StrOutputParser()\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002D6E63F3E20>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002D6E642D2D0>, model_name='Llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********'))), kwargs={}, config={'run_name': 'chat_retriever_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_aware_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a62f5ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"), # Placeholder for chat history\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4253844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm,qa_prompt)\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a47b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "question = \"What are Langchain components?\"\n",
    "response_1 = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "\n",
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=question),\n",
    "        AIMessage(content=response_1['answer'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "question2 = \"What are the different types of agents in Langchain?\"\n",
    "response_2 = rag_chain.invoke({\"input\": question2, \"chat_history\": chat_history})\n",
    "\n",
    "print(response_2['answer'])\"\"\"\n",
    "\n",
    "from langchain_core.messages import AIMessage,HumanMessage\n",
    "chat_history=[]\n",
    "question=\"What is Self-Reflection\"\n",
    "response1=rag_chain.invoke({\"input\":question,\"chat_history\":chat_history})\n",
    "\n",
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=question),\n",
    "        AIMessage(content=response1['answer'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "question2=\"Tell me more about it?\"\n",
    "response2=rag_chain.invoke({\"input\":question,\"chat_history\":chat_history})\n",
    "print(response2['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff0581a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
